{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2d1251",
   "metadata": {},
   "source": [
    "# Notebook 02: Glue & Athena Data Catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af4419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a299a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket: nfci-forecasting-306617143793\n",
      "Region: us-east-1\n",
      "Glue Database: nfci_database\n",
      "Glue Crawler: nfci-raw-data-crawler\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "#load config\n",
    "from config.config import (\n",
    "    BUCKET_NAME,\n",
    "    AWS_REGION,\n",
    "    S3_PREFIX,\n",
    "    RAW_DATA_FILENAME,\n",
    "    GLUE_DATABASE_NAME,\n",
    "    GLUE_CRAWLER_NAME,\n",
    "    get_s3_uri,\n",
    ")\n",
    "\n",
    "print(f\"Bucket: {BUCKET_NAME}\")\n",
    "print(f\"Region: {AWS_REGION}\")\n",
    "print(f\"Glue Database: {GLUE_DATABASE_NAME}\")\n",
    "print(f\"Glue Crawler: {GLUE_CRAWLER_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfff65de",
   "metadata": {},
   "source": [
    "### create glue and athena AWS clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb600e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glue client created\n",
      "Athena client created\n"
     ]
    }
   ],
   "source": [
    "# Create clients\n",
    "glue_client = boto3.client(\"glue\", region_name=AWS_REGION)\n",
    "athena_client = boto3.client(\"athena\", region_name=AWS_REGION)\n",
    "\n",
    "print(\"Glue client created\")\n",
    "print(\"Athena client created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8cee5",
   "metadata": {},
   "source": [
    "### create glue database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f663675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'nfci_database' created successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    glue_client.create_database(\n",
    "        DatabaseInput={\n",
    "            \"Name\": GLUE_DATABASE_NAME,\n",
    "            \"Description\": \"Database for NFCI Forecasting Project\",\n",
    "        }\n",
    "    )\n",
    "    print(f\"Database '{GLUE_DATABASE_NAME}' created successfully\")\n",
    "except ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"AlreadyExistsException\":\n",
    "        print(f\"Database '{GLUE_DATABASE_NAME}' already exists\")\n",
    "    else:\n",
    "        print(f\"Error creating database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f35ae3",
   "metadata": {},
   "source": [
    "### Create Glue Crawler\n",
    "- create glue IAM role and policy\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c88923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# IAM client\n",
    "iam_client = boto3.client(\"iam\")\n",
    "\n",
    "# Role name for Glue\n",
    "GLUE_ROLE_NAME = \"nfci-glue-crawler-role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e061112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glue_role(role_name: str, bucket_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Create an IAM role for Glue Crawler with necessary permissions.\n",
    "    \n",
    "    Returns the role ARN.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Trust policy - allows Glue service to assume this role\n",
    "    trust_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"glue.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # S3 policy - allows access to our specific bucket\n",
    "    s3_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:PutObject\",\n",
    "                    \"s3:ListBucket\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    f\"arn:aws:s3:::{bucket_name}\",\n",
    "                    f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Create the role\n",
    "        response = iam_client.create_role(\n",
    "            RoleName=role_name,\n",
    "            AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "            Description=\"IAM role for Glue Crawler - NFCI project\"\n",
    "        )\n",
    "        role_arn = response[\"Role\"][\"Arn\"]\n",
    "        print(f\"✓ Created role: {role_name}\")\n",
    "        \n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "            # Role exists, get its ARN\n",
    "            response = iam_client.get_role(RoleName=role_name)\n",
    "            role_arn = response[\"Role\"][\"Arn\"]\n",
    "            print(f\"✓ Role already exists: {role_name}\")\n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "    # Attach the AWS managed Glue service policy\n",
    "    try:\n",
    "        iam_client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole\"\n",
    "        )\n",
    "        print(f\"Attached AWSGlueServiceRole policy\")\n",
    "    except ClientError as e:\n",
    "        if \"already\" not in str(e).lower():\n",
    "            print(f\"  Note: {e}\")\n",
    "    \n",
    "    # Step 3: Create and attach custom S3 policy for our bucket\n",
    "    s3_policy_name = f\"{role_name}-s3-policy\"\n",
    "    \n",
    "    try:\n",
    "        iam_client.put_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyName=s3_policy_name,\n",
    "            PolicyDocument=json.dumps(s3_policy)\n",
    "        )\n",
    "        print(f\"Attached S3 access policy for bucket: {bucket_name}\")\n",
    "    except ClientError as e:\n",
    "        print(f\"  Note: {e}\")\n",
    "    \n",
    "    return role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deeb299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created role: nfci-glue-crawler-role\n",
      "Attached AWSGlueServiceRole policy\n",
      "Attached S3 access policy for bucket: nfci-forecasting-306617143793\n",
      "\n",
      "Glue Role ARN: arn:aws:iam::306617143793:role/nfci-glue-crawler-role\n"
     ]
    }
   ],
   "source": [
    "# Create the Glue role\n",
    "GLUE_ROLE_ARN = create_glue_role(GLUE_ROLE_NAME, BUCKET_NAME)\n",
    "print(f\"\\nGlue Role ARN: {GLUE_ROLE_ARN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3453fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_glue_crawler(\n",
    "    crawler_name: str,\n",
    "    role_arn: str,\n",
    "    database_name: str,\n",
    "    s3_target_path: str,\n",
    "    table_prefix: str = \"\"\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Create a Glue Crawler to catalog data in S3.\n",
    "    \n",
    "    Parameters:\n",
    "        crawler_name: Name for the crawler\n",
    "        role_arn: IAM role ARN with Glue and S3 permissions\n",
    "        database_name: Target Glue database for discovered tables\n",
    "        s3_target_path: S3 path to crawl (e.g., s3://bucket/prefix/)\n",
    "        table_prefix: Optional prefix for table names\n",
    "    \"\"\"\n",
    "    try:\n",
    "        glue_client.create_crawler(\n",
    "            Name=crawler_name,\n",
    "            Role=role_arn,\n",
    "            DatabaseName=database_name,\n",
    "            Description=f\"Crawler for {s3_target_path}\",\n",
    "            Targets={\n",
    "                \"S3Targets\": [\n",
    "                    {\n",
    "                        \"Path\": s3_target_path,\n",
    "                        \"Exclusions\": []  # No exclusions\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            TablePrefix=table_prefix,\n",
    "            SchemaChangePolicy={\n",
    "                \"UpdateBehavior\": \"UPDATE_IN_DATABASE\",  # Update existing tables\n",
    "                \"DeleteBehavior\": \"LOG\"  # Log deleted objects, don't remove from catalog\n",
    "            },\n",
    "            RecrawlPolicy={\n",
    "                \"RecrawlBehavior\": \"CRAWL_EVERYTHING\"  # Re-crawl all data each time\n",
    "            },\n",
    "            Configuration='{\"Version\":1.0,\"CrawlerOutput\":{\"Partitions\":{\"AddOrUpdateBehavior\":\"InheritFromTable\"}}}'\n",
    "        )\n",
    "        print(f\"✓ Crawler '{crawler_name}' created successfully\")\n",
    "        return True\n",
    "        \n",
    "    except ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"AlreadyExistsException\":\n",
    "            print(f\"Crawler '{crawler_name}' already exists\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"✗ Error creating crawler: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb07570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawler will scan: s3://nfci-forecasting-306617143793/data/raw/\n",
      "✓ Crawler 'nfci-raw-data-crawler' created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define S3 path for raw data\n",
    "raw_data_s3_path = f\"s3://{BUCKET_NAME}/{S3_PREFIX['raw']}/\"\n",
    "print(f\"Crawler will scan: {raw_data_s3_path}\")\n",
    "\n",
    "# Create the crawler\n",
    "create_glue_crawler(\n",
    "    crawler_name=GLUE_CRAWLER_NAME,\n",
    "    role_arn=GLUE_ROLE_ARN,\n",
    "    database_name=GLUE_DATABASE_NAME,\n",
    "    s3_target_path=raw_data_s3_path,\n",
    "    table_prefix=\"\"  # No prefix - table will be named 'raw'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50349f20",
   "metadata": {},
   "source": [
    "#### Run crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51365ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMaker",
   "language": "python",
   "name": "sagemaker_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
